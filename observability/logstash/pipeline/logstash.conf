input {
  tcp {
    port => 5000
    codec => json
  }

  # Can be extended to receive logs from services
  # via TCP, HTTP, or file inputs
}

filter {
  # Parse JSON logs
  if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
  }

  # Extract trace information
  if [traceId] {
    mutate {
      add_field => { "trace_id" => "%{traceId}" }
    }
  }

  if [spanId] {
    mutate {
      add_field => { "span_id" => "%{spanId}" }
    }
  }

  # Add timestamp
  date {
    match => [ "timestamp", "ISO8601" ]
    target => "@timestamp"
  }

  # Service name extraction
  if [logger_name] =~ /^com\.banking\.([^.]+)/ {
    grok {
      match => { "logger_name" => "^com\.banking\.(?<service_name>[^.]+)" }
    }
  }

  # Log level normalization
  mutate {
    uppercase => [ "level" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "banking-logs-%{+YYYY.MM.dd}"
    template_name => "banking-logs"
  }

  # Debug output (can be removed in production)
  stdout {
    codec => rubydebug
  }
}
